# AI_project_master/app.py
import streamlit as st
import pandas as pd
import joblib, json, time
from pathlib import Path

st.set_page_config(page_title="Earthquake Alert", page_icon="üåé", layout="wide")

# ---- Paths ----
BASE = Path("AI_project_master")
DATA_PATH   = BASE / "data" / "earthquakes.csv"
MODEL_PATH  = BASE / "models" / "earthquake_model.pkl"
ENC_PATH    = BASE / "models" / "label_encoder.pkl"
ANN_PATH    = BASE / "storage" / "public_announcements.json"
METRICS_CSV = BASE / "metrics" / "metrics.csv"

st.title("üåé ‡∏£‡∏∞‡∏ö‡∏ö‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡πÅ‡∏ú‡πà‡∏ô‡∏î‡∏¥‡∏ô‡πÑ‡∏´‡∏ß")
st.caption("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå/‡∏Å‡∏£‡∏≠‡∏Å‡∏Ñ‡πà‡∏≤ ‚Üí ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢ AI ‚Üí ‡πÄ‡∏ú‡∏¢‡πÅ‡∏û‡∏£‡πà‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®  ‚Ä¢  (‡πÇ‡∏°‡πÄ‡∏î‡∏•: Decision Tree)")

# ---- Check required files ----
missing = [p for p in [DATA_PATH, MODEL_PATH, ENC_PATH] if not Path(p).exists()]
if missing:
    st.error("‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏û‡∏ö:\n" + "\n".join(f"- {p}" for p in missing))
    st.info("‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÉ‡∏™‡πà earthquakes.csv ‡∏ñ‡∏π‡∏Å‡∏ó‡∏µ‡πà ‡πÅ‡∏•‡∏∞‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ô train.py ‡πÅ‡∏•‡πâ‡∏ß")
    st.stop()

# ---- Load data/model/encoder ----
df = pd.read_csv(DATA_PATH)
model = joblib.load(MODEL_PATH)
le    = joblib.load(ENC_PATH)

# Basic numeric cleaning for UI
for col in ["magnitude","depth","cdi","mmi","sig"]:
    if col in df.columns:
        df[col] = pd.to_numeric(df[col], errors="coerce")
        df[col].fillna(df[col].median(), inplace=True)

st.write(f"üì¶ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(df):,} ‡πÅ‡∏ñ‡∏ß")
with st.expander("‡∏î‡∏π‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (5 ‡πÅ‡∏ñ‡∏ß)"):
    st.dataframe(df.head(5), use_container_width=True)

# ---- Training Results (‡∏ï‡∏≠‡∏ö‡πÇ‡∏à‡∏ó‡∏¢‡πå‡∏Ç‡πâ‡∏≠ 4) ----
with st.expander("üìä Training Results (‡∏´‡∏•‡∏≤‡∏¢ features/parameters)"):
    if METRICS_CSV.exists():
        mdf = pd.read_csv(METRICS_CSV)
        if not mdf.empty:
            st.dataframe(mdf, use_container_width=True)
            top = mdf.sort_values("accuracy", ascending=False).iloc[0]
            st.success(
                f"‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å: feature_set = {top['feature_set']}, "
                f"params = {top['params']}, accuracy = {top['accuracy']}"
            )
        else:
            st.info("metrics.csv ‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤ ‚Äî ‡πÇ‡∏õ‡∏£‡∏î‡∏£‡∏±‡∏ô train.py ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå")
    else:
        st.info("‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå metrics.csv ‚Äî ‡πÇ‡∏õ‡∏£‡∏î‡∏£‡∏±‡∏ô train.py ‡∏Å‡πà‡∏≠‡∏ô")

# ---- Officer section ----
st.subheader("üëÆ‚Äç‚ôÄÔ∏è ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏£‡∏≠‡∏Å‡∏Ñ‡πà‡∏≤‡πÄ‡∏≠‡∏á ‡πÅ‡∏•‡πâ‡∏ß‡∏Å‡∏î‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢")
latest = df.tail(200).reset_index(drop=True)

left, right = st.columns([1,1])
with left:
    st.markdown("**‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå (200 ‡πÅ‡∏ñ‡∏ß‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î)**")
    idx = st.number_input("‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç‡πÅ‡∏ñ‡∏ß:", min_value=0, max_value=len(latest)-1,
                          value=len(latest)-1, step=1)
    row = latest.iloc[int(idx)].to_dict()

with right:
    st.markdown("**‡∏Å‡∏£‡∏≠‡∏Å‡∏Ñ‡πà‡∏≤‡πÄ‡∏≠‡∏á (‡∏ó‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏î‡πâ)**")

    def defval(k, default):
        v = row.get(k, default)
        try:
            return float(v) if pd.notna(v) else float(default)
        except Exception:
            return float(default)

    mag = st.number_input("magnitude", value=defval("magnitude", 5.0))
    dep = st.number_input("depth",     value=defval("depth", 10.0))
    cdi = st.number_input("cdi",       value=defval("cdi", 3.0))
    mmi = st.number_input("mmi",       value=defval("mmi", 3.0))
    sig = st.number_input("sig",       value=defval("sig", 300.0))

    inputs = pd.DataFrame([{
        "magnitude": mag, "depth": dep, "cdi": cdi, "mmi": mmi, "sig": sig
    }])

if st.button("üß† ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢ AI", use_container_width=True):
    # ‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏à‡∏£‡∏¥‡∏á‡πÉ‡∏ô dataset/‡∏ï‡∏≠‡∏ô‡πÄ‡∏ó‡∏£‡∏ô
    feat_cols = [c for c in ["magnitude","depth","cdi","mmi","sig"] if c in df.columns]
    X = inputs[feat_cols]
    y_id = model.predict(X)[0]
    y_label = le.inverse_transform([y_id])[0]
    st.success(f"‡∏ú‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô: **{str(y_label).upper()}**")
    st.session_state["last_pred"] = {
        "risk": str(y_label),
        "inputs": inputs.iloc[0].to_dict(),
        "region": str(row.get("place", "Affected area")) if "place" in row else "Affected area"
    }

# ---- Publish announcement ----
if "last_pred" in st.session_state:
    st.divider()
    st.subheader("üì¢ ‡πÄ‡∏ú‡∏¢‡πÅ‡∏û‡∏£‡πà‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏® (‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡∏ä‡∏ô‡∏à‡∏∞‡πÄ‡∏´‡πá‡∏ô‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á)")
    pred = st.session_state["last_pred"]
    region = st.text_input("‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà/‡∏†‡∏π‡∏°‡∏¥‡∏†‡∏≤‡∏Ñ", value=pred["region"])
    msg_default = f"‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡πÄ‡∏´‡∏ï‡∏∏‡∏™‡∏±‡πà‡∏ô‡∏™‡∏∞‡πÄ‡∏ó‡∏∑‡∏≠‡∏ô‡∏£‡∏∞‡∏î‡∏±‡∏ö {pred['risk'].upper()} ‚Äî ‡πÇ‡∏õ‡∏£‡∏î‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡∏ï‡∏≤‡∏°‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢"
    message = st.text_area("‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®", value=msg_default, height=80)
    tips = ["‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ï‡πâ‡πÇ‡∏ï‡πä‡∏∞/‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏Ç‡πá‡∏á‡πÅ‡∏£‡∏á", "‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡∏•‡∏¥‡∏ü‡∏ï‡πå/‡∏Å‡∏£‡∏∞‡∏à‡∏Å", "‡∏õ‡∏¥‡∏î‡πÅ‡∏Å‡πä‡∏™/‡πÑ‡∏ü‡∏ü‡πâ‡∏≤"]

    if st.button("‚úÖ ‡πÄ‡∏ú‡∏¢‡πÅ‡∏û‡∏£‡πà‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®", type="primary", use_container_width=True):
        ANN_PATH.parent.mkdir(parents=True, exist_ok=True)
        doc = {
            "last_updated": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
            "announcements": [{
                "id": str(int(time.time())),
                "region": region,
                "risk_level": pred["risk"],
                "message": message,
                "tips": tips,
                "inputs": pred["inputs"]
            }]
        }
        with open(ANN_PATH, "w", encoding="utf-8") as f:
            json.dump(doc, f, ensure_ascii=False, indent=2)
        st.success("‡πÄ‡∏ú‡∏¢‡πÅ‡∏û‡∏£‡πà‡πÅ‡∏•‡πâ‡∏ß! ‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏•‡∏á‡πÑ‡∏õ‡∏î‡∏π‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢ üëá")

# ---- Announcements (public view) ----
st.divider()
st.subheader("üö® ‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏® (‡πÅ‡∏™‡∏î‡∏á‡∏ï‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡∏ä‡∏ô)")
if not ANN_PATH.exists():
    st.info("‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î")
else:
    ann = json.load(open(ANN_PATH, encoding="utf-8"))
    st.caption(f"‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î: {ann.get('last_updated','-')}")
    for a in ann.get("announcements", []):
        level = str(a.get("risk_level","")).lower()
        color = {"green":"üü¢","yellow":"üü°","orange":"üü†","red":"üî¥"}.get(level, "üî∂")
        st.markdown(f"### {color} ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô: **{str(a.get('risk_level','')).upper()}**")
        st.write(f"‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà: **{a.get('region','-')}**")
        if a.get("message"):
            st.write(a["message"])
        if a.get("tips"):
            st.write("‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:")
            for t in a["tips"]:
                st.write(f"- {t}")

# ---- Credits (‡∏ï‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠ 2 ‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≤) ----
with st.expander("‚ÑπÔ∏è Dataset Source / ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á"):
    st.write("Dataset: Kaggle ‚Äì Earthquake Alert Prediction (‡∏ú‡∏π‡πâ‡∏à‡∏±‡∏î‡∏ó‡∏≥: Ahmed Uzaki) ‡∏´‡∏£‡∏∑‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á (‡πÇ‡∏õ‡∏£‡∏î‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≤‡πÉ‡∏ô‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì)")
